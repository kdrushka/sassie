{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509908b4-a581-42a7-bdef-b886b60c98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run through all files, open the file, and check if there are *any* data in our lat/lon rannge\n",
    "L3files = glob.glob('downloads/RSS_smap_SSS_L3*') # use L3 SMAP - requires having one file stored locally\n",
    "\n",
    "\n",
    "# loads a single data file ...\n",
    "ds = xr.open_mfdataset(outfile, engine='h5netcdf', phony_dims='sort')\n",
    "# phony_dim_0 is swath x, phony_dim_1 is swath y, phony_dim_2 is related to SMAP ambiguity, we can ignore this here\n",
    "ds = ds.rename_dims({'phony_dim_0':'swath_x', 'phony_dim_1':'swath_y'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f47def-99ff-43ec-bc3b-0f87493a3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are lon/lat data in our domain:\n",
    "lons = np.reshape(ds.lon.values,[1,-1])\n",
    "lats = np.reshape(ds.lat.values,[1,-1])\n",
    "sss = np.reshape(ds.smap_sss.values,[1,-1])\n",
    "\n",
    "i = ((lons > lonrange[0]) & (lons < lonrange[1]) & (lats > latrange[0]) & (lats < latrange[1])) \n",
    "sss = sss[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a18818-05de-416b-9632-389b5629c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# follow severine's example to regrid & subsample\n",
    "L3files = glob.glob('downloads/RSS_smap_SSS_L3*') # use L3 SMAP - requires having one file stored locally\n",
    "ds_grid = xr.open_dataset(L3files[0])\n",
    "\n",
    "# define grid lat/lon mesh\n",
    "longrid = ds_grid.lon.values\n",
    "latgrid = ds_grid.lat.values\n",
    "LOgrid, LAgrid = np.meshgrid(longrid, latgrid)\n",
    "print(LOgrid.shape,LAgrid.shape)\n",
    "\n",
    "# use pyresample to define a target grid\n",
    "target = pr.SwathDefinition(LOgrid, LAgrid)\n",
    "\n",
    "# and the source data\n",
    "lons = ds.lon.values\n",
    "lats = ds.lat.values \n",
    "source = pr.SwathDefinition(lons, lats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e62a4-8438-4a66-8b80-d3d7c45cbc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resample:\n",
    "sss = ds.smap_sss.values\n",
    "result, stddev, counts = resample_gauss(\n",
    "    source,\n",
    "    sss,\n",
    "    target,\n",
    "    radius_of_influence=175000,  \n",
    "    sigmas=25000,\n",
    "    neighbours=100,\n",
    "    fill_value=np.nan,\n",
    "    with_uncert=True,\n",
    ")\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1607e-833a-46e9-ba47-9a9f4e12e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find non-nan data:\n",
    "# sss = ds.smap_sss\n",
    "\n",
    "# Severine's code identifies fill value, but the L2 SMAP data doesn't have this field\n",
    "# - instead, should prob use quality code :/\n",
    "# attrs = {}\n",
    "# for k, v in ds.smap_sss.attrs.items():\n",
    "#         if isinstance(v, bytes):\n",
    "#             attrs[k] = v.decode('utf-8')\n",
    "#         else:\n",
    "#             attrs[k] = v\n",
    "#         print(k, ' ', attrs[k])\n",
    "# # attrs['_FillValue']\n",
    "# sss = numpy.where(ds.smap_sss < attrs['_FillValue'], ds.smap_sss, numpy.nan)\n",
    "sss = np.where(ds.smap_sss > 0, ds.smap_sss, np.nan)\n",
    "nnans = ~np.isnan(sss)\n",
    "sss = sss[nnans]\n",
    "\n",
    "lons = ds.lon.values[nnans]\n",
    "lats = ds.lat.values[nnans]  \n",
    "lons = (lons + 180) % 360 - 180\n",
    "print(sss.shape, lons.shape, lats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e007634-315f-4196-b7b8-f79ded0a3630",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumx = np.where((ds.lon<lonrange[0], ds.lon>lonrange[1]), ds.lon, np.nan)\n",
    "dumy = np.where((ds.lat<latrange[0], ds.lat>latrange[1]), ds.lat, np.nan)\n",
    "# dum = np.where((ds.lon>lonrange[0], ds.lon<lonrange[1]), ds.smap_sss, np.nan)\n",
    "plt.plot(dumx[0,:,:],dumy[0,:,:],'.')\n",
    "# dum.shape\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b92d53-af2d-4230-8fd0-87bba21a72d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset data spatially\n",
    "# ds.where(ds.lon>lonrange[0] and ds.lat<lonrange[1])\n",
    "# ds.where(ds.lon>lonrange[0], smap_sss)\n",
    "# xr.where(ds.lon>lonrange[0], ds.smap_sss, 1).plot()\n",
    "# ds.lon.plot()\n",
    "# ds.sel(lon>lonrange[0])\n",
    "\n",
    "# ideep = ( subsampled_data.dep.values == subsampled_data.dep.values.min() )\n",
    "# this_var_onedep = sdata[vbl].where(sdata.dep == zpl, drop=True)\n",
    "\n",
    "\n",
    "i = ( ds.lon.values>lonrange[0] )\n",
    "plt.plot(ds.lon.sel("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ac3442-9f4a-4656-9fd3-5aea71ef4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from pyresample import geometry, geo_filter\n",
    "lons = np.array([-170, -30, 30, 170])\n",
    "lats = np.array([20, -40, 50, -80])\n",
    "swath_def = geometry.SwathDefinition(lons, lats)\n",
    "\n",
    "data = np.array([1, 2, 3, 4])\n",
    "filter_area = geometry.AreaDefinition('test', 'test', 'test',\n",
    "                                      {'proj' : 'eqc', 'lon_0' : 0.0, 'lat_0' : 0.0},\n",
    "                                      8, 8,\n",
    "                                      (-20037508.34, -10018754.17, 20037508.34, 10018754.17)\n",
    "                                     )\n",
    "filter = np.array([[1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                   [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                   [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                   [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                   [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                   [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                   [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                  ])\n",
    "grid_filter = geo_filter.GridFilter(filter_area, filter)\n",
    "swath_def_filtered, data_filtered = grid_filter.filter(swath_def, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0bb6e5-9de6-4919-b421-9d23a2e28be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIS SST\n",
    "\n",
    "provider = 'POCLOUD'\n",
    "url = 'https://cmr.earthdata.nasa.gov/search/collections.umm_json'\n",
    "response = requests.get(url,\n",
    "                        params={\n",
    "                            'cloud_hosted': 'True',\n",
    "                            'has_granules': 'True',\n",
    "                            'provider': provider,\n",
    "                            'page_size': 300,\n",
    "                            'temporal': date_range \n",
    "                        },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                        }\n",
    "                       )\n",
    "response.headers['cmr-hits']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fae7e5-771e-4223-8fc4-8b1768f0bad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each response in the catalog and print the respective concept ID\n",
    "# for r in response.json()['items']:\n",
    "#     print('{} ==> '.format(r['meta']['s3-links'][0].split('/')[1]), r['meta']['concept-id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cddf72f-625f-4baf-883d-8a59b8204d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading credentials for direct access\n",
    "def begin_s3_direct_access(url: str=\"https://archive.podaac.earthdata.nasa.gov/s3credentials\"):\n",
    "    response = requests.get(url).json()\n",
    "    return s3fs.S3FileSystem(key=response['accessKeyId'],\n",
    "                             secret=response['secretAccessKey'],\n",
    "                             token=response['sessionToken'],\n",
    "                             client_kwargs={'region_name':'us-west-2'})\n",
    "\n",
    "fs = begin_s3_direct_access()\n",
    "\n",
    "type(fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c232d8-4a3a-4bfd-a171-ce04a4225dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://cmr.earthdata.nasa.gov/search/granules'\n",
    "response = requests.get(url, \n",
    "                        params={\n",
    "                            'concept_id': 'C2036880650-POCLOUD',\n",
    "                            'temporal': date_range,\n",
    "                            'bounding_box': bounding_box, \n",
    "                            'page_size': 200,\n",
    "                            },\n",
    "                        headers={\n",
    "                            'Accept': 'application/json'\n",
    "                            }\n",
    "                       )\n",
    "print(response)\n",
    "print(response.headers['CMR-Hits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d746c-d095-429e-a142-a6c59f80bdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "granules_url = []\n",
    "for gran in response.json()['feed']['entry']:\n",
    "    granules_url.append(gran['links'][0]['href'])\n",
    "granules_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805d3823-ac53-4fed-bf2d-272dbd7c02b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the same file exists in NRT and non-NRT (ie, DT), skip the NRT version (there is definitely a cleaner way to do this...)\n",
    "for gran in granules_url:\n",
    "    if 'NRT' in gran and (gran.rsplit('NRT.nc', 1)[0] + 'nc') in granules_url: # if this has NRT *and* a non-NRT version exists\n",
    "        granules_url.remove(gran)\n",
    "print(granules_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69048018-c0f0-41b8-a3b5-f5232af26739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_time(ds):\n",
    "    t0 = np.datetime64(pd.to_datetime(ds.time_coverage_start).date())\n",
    "    return ds.expand_dims(time=[t0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a523fd-219a-4d51-b504-1071ab7568a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file(s)\n",
    "# use sel and slice to get our region. MODIS SSTs have lat from + to -, so put the bigger lat value first in the slice\n",
    "file_list =  [fs.open(file) for file in granules_url]\n",
    "ds_modis = xr.open_mfdataset(file_list, preprocess=extract_time, engine='h5netcdf',concat_dim='time', combine='nested').sel(lon=slice(lonrange[0], lonrange[1]), lat=slice(latrange[1], latrange[0]))\n",
    "ds_modis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75f0e9a-debc-4f51-824e-359b1f408216",
   "metadata": {},
   "source": [
    "### In situ data from UpTempO buoys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd618c-e229-4d5a-9004-6ce5d8e34b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for now, just pick a single buoy & download it locally using wget (if new)\n",
    "buoy_url = 'http://psc.apl.washington.edu/UpTempO/WebDATA/'\n",
    "\n",
    "# from pyresample import geometry, geo_filter\n",
    "lons = np.array([-170, -30, 30, 170])\n",
    "lats = np.array([20, -40, 50, -80])\n",
    "swath_def = geometry.SwathDefinition(lons, lats)\n",
    "\n",
    "data = np.array([1, 2, 3, 4])\n",
    "filter_area = geometry.AreaDefinition('test', 'test', 'test',\n",
    "                                      {'proj' : 'eqc', 'lon_0' : 0.0, 'lat_0' : 0.0},\n",
    "                                      8, 8,\n",
    "                                      (-20037508.34, -10018754.17, 20037508.34, 10018754.17)\n",
    "                                     )\n",
    "filter = np.array([[1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                   [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                   [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                   [1, 1, 1, 1, 0, 0, 0, 0],\n",
    "                   [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                   [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                   [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                   [0, 0, 0, 0, 1, 1, 1, 1],\n",
    "                  ])\n",
    "grid_filter = geo_filter.GridFilter(filter_area, filter)\n",
    "swath_def_filtered, data_filtered = grid_filter.filter(swath_def, data)\n",
    "\n",
    "buoy_file = 'UpTempO_2019_02_SIZRS-20211117.dat'\n",
    "buoy_url + buoy_file\n",
    "!wget -N {buoy_url + buoy_file} -P downloads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842988c-f893-4fbb-9058-cee47b5fa755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this file, we want to skip the first 35 lines (header). can later generalize this\n",
    "filename = (f'downloads/{buoy_file}')\n",
    "f = open(filename,'r')\n",
    "# data = f.readlines()[35:]\n",
    "data = f.readlines()[35:40] # start with a small # of rows\n",
    "f.close()\n",
    "\n",
    "# %DATA COLUMNS:\n",
    "# % 0 = year\n",
    "# % 1 = month\n",
    "# % 2 = day\n",
    "# % 3 = hour (GMT)\n",
    "# % 4 = Latitude (N)\n",
    "# % 5 = Longitude (E)\n",
    "# % 6 = Ocean Pressure (dB) at Sensor #1(Nominal Depth = 20.0 m)\n",
    "# % 7 = Ocean Pressure (dB) at Sensor #2(Nominal Depth = 40.0 m)\n",
    "# % 8 = Ocean Pressure (dB) at Sensor #3(Nominal Depth = 60.0 m)\n",
    "# % 9 = Temperature at nominal depth 0.0 (m)\n",
    "# % 10 = Temperature at nominal depth 2.5 (m)\n",
    "# % 11 = Temperature at nominal depth 5.0 (m)\n",
    "# % 12 = Temperature at nominal depth 7.5 (m)\n",
    "# % 13 = Temperature at nominal depth 10.0 (m)\n",
    "# % 14 = Temperature at nominal depth 15.0 (m)\n",
    "# % 15 = Temperature at nominal depth 20.0 (m)\n",
    "# % 16 = Temperature at nominal depth 25.0 (m)\n",
    "# % 17 = Temperature at nominal depth 30.0 (m)\n",
    "# % 18 = Temperature at nominal depth 35.0 (m)\n",
    "# % 19 = Temperature at nominal depth 40.0 (m)\n",
    "# % 20 = Temperature at nominal depth 50.0 (m)\n",
    "# % 21 = Temperature at nominal depth 60.0 (m)\n",
    "# % 22 = Sea Level Pressure (mBar)\n",
    "# % 23 = Battery Voltage (V)\n",
    "# % 24 = Submergence Percent\n",
    "# 2019 08 14 20.3500 72.013322 -149.817103 0.250 0.431 0.611 13.29 5.022276 3.85962 3.70969 3.468275 3.823188 3.630601 3.738509 3.441308 3.728554 3.573352 3.425621 3.545923 1011.2 12.8 0\n",
    "# data[[:,1]]\n",
    "\n",
    "df = pd.read_csv(filename, sep=' ', skiprows=35, names=[\"year\", \"month\", \"day\", \"hour\", \"lat\", \n",
    "                                               \"lon\", \"p20\", \"p40\", \"p60\", \"T0\", \"T2p5\", \n",
    "                                               \"T5\", \"T7p5\", \"T10\", \"T15\", \"T20\", \"T25\", \n",
    "                                               \"T30\", \"T35\", \"T40\", \"T50\",\"T60\", \"SLP\", \"voltage\", \"sub_perc\"],\n",
    "                parse_dates= {\"date\" : [\"year\",\"month\",\"day\",\"hour\"]})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf7b01b-619f-4ad9-a71a-e2e20a0b869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not quite right but close!\n",
    "# df['dates'] = pd.to_datetime({df['year'],df['month'], df['day']}, format='%Y%m%d')\n",
    "\n",
    "plt.plot(df['l'],df['T0'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c3975e-b4f6-470a-badd-11eaaeb75a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.where(df['T0']!=-999)\n",
    "\n",
    "\n",
    "# plt.scatter(df['lon'],df['lat'],c=df['T0'],vmin=-5, vmax=5)\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad22cd3-39ec-4b63-948d-fe17abd94c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(data_vars[lon])\n",
    "# plt.show()\n",
    "# attrs['sss_smap']\n",
    "# smap_l2 = xr.Dataset(data_vars)\n",
    "# data_vars?\n",
    "\n",
    "# data_vars (dict-like, optional) â€“ A mapping from variable names to DataArray objects,\n",
    "# Variable objects or to tuples of the form (dims, data[, attrs]) which can be used as arguments \n",
    "# to create a new Variable. Each dimension must have the same length in all variables in which it appears.\n",
    "\n",
    "# The following notations are accepted:\n",
    "\n",
    "#     mapping {var name: DataArray}\n",
    "\n",
    "#     mapping {var name: Variable}\n",
    "\n",
    "#     mapping {var name: (dimension name, array-like)}\n",
    "\n",
    "#     mapping {var name: (tuple of dimension names, array-like)}\n",
    "\n",
    "#     mapping {dimension name: array-like} (it will be automatically moved to coords, see below)\n",
    "\n",
    "# Each dimension must have the same length in all variables in which it appears.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
